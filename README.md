# BertPooled. 
This mini project *BertPooled* aims to reduce the computing burden of language models by simply adding a pooling layer.    
  
Though it would have been best if I pretrained a Language Model with Pooling Layers from scratch in order to proove whether such attempts are meaningful, due to realistic problems I had to settle by confirming that additional researchs may be worthwile after conducting few experiments with the concept.
